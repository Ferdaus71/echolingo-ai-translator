# -*- coding: utf-8 -*-
"""echolingo-ai-translator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RUdUiV2lHu7A_hRHgrfX8k7sWpqQh80h

Install Dependencies
"""

!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
 !pip install -q openai-whisper==20240930
 !apt-get -y install -qq ffmpeg
 !pip install -q transformers==4.45.2 accelerate gradio librosa soundfile

"""Import Libraries & Load Models

"""

import torch, whisper, gradio as gr
from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print("âœ… Device:", DEVICE)


whisper_model = whisper.load_model("small", device=DEVICE)
print("âœ… Whisper loaded.")


TRANSLATOR = "facebook/m2m100_418M"
translator_tokenizer = M2M100Tokenizer.from_pretrained(TRANSLATOR)
translator_model = M2M100ForConditionalGeneration.from_pretrained(TRANSLATOR).to(DEVICE)
print("âœ… Translator loaded.")

"""Language Options"""

LANGUAGE_OPTIONS = {
    "Auto (use detected)": "auto",
    "English": "en",
    "Bangla / Bengali": "bn",
    "Hindi": "hi",
    "Urdu": "ur",
    "Arabic": "ar",
    "French": "fr",
    "Spanish": "es",
    "German": "de",
    "Portuguese": "pt",
    "Russian": "ru",
}

def transcribe_audio(audio_input):
    """Works with dict or path"""
    try:
        if isinstance(audio_input, dict):
            audio_path = audio_input.get("name") or audio_input.get("path")
        else:
            audio_path = audio_input
        if not audio_path:
            return "", "unknown", "No audio file received"
        print("ğŸ§ Transcribing:", audio_path)
        result = whisper_model.transcribe(audio_path)
        text = result.get("text", "").strip()
        lang = result.get("language", "unknown")
        return text, lang, "Transcription complete"
    except Exception as e:
        return "", "error", f"Transcription failed: {e}"

def translate_text(text, src_lang, tgt_lang):
    try:
        if not text or not tgt_lang or tgt_lang == "auto":
            return text
        if src_lang in ["auto", "unknown", None]:
            src_lang = "en"
        translator_tokenizer.src_lang = src_lang
        encoded = translator_tokenizer(text, return_tensors="pt", truncation=True).to(DEVICE)
        forced_lang_id = translator_tokenizer.get_lang_id(tgt_lang)
        gen = translator_model.generate(**encoded, forced_bos_token_id=forced_lang_id, max_length=512)
        return translator_tokenizer.batch_decode(gen, skip_special_tokens=True)[0]
    except Exception as e:
        return f"[Translation error: {e}]"

"""Audio input & target name of language"""

def process(audio_input, target_lang_name):
    try:
        status = "â³ Processing..."
        text, detected_lang, trans_status = transcribe_audio(audio_input)
        tgt_code = LANGUAGE_OPTIONS.get(target_lang_name, "auto")
        translated = translate_text(text, detected_lang, tgt_code)
        return f"{trans_status}", text, translated
    except Exception as e:
        return f"âŒ Error: {e}", "", ""

"""Custome Dashboard"""

custom_css = """
body {
  background: linear-gradient(135deg, #1e3a8a, #0f172a);
  color: #f8fafc;
}
.gradio-container {
  font-family: 'Poppins', sans-serif;
}
#title-bar {
  background: linear-gradient(90deg, #2563eb, #6366f1);
  color: white;
  text-align: center;
  padding: 15px;
  border-radius: 12px;
  font-size: 22px;
  box-shadow: 0 0 15px rgba(99,102,241,0.6);
  margin-bottom: 20px;
}
button {
  background: white !important;
  color: #1e3a8a !important;
  border-radius: 10px !important;
  font-weight: 600 !important;
  border: 2px solid #1e3a8a !important;
  transition: all 0.3s ease;
}
button:hover {
  background: #1e3a8a !important;
  color: white !important;
  transform: scale(1.05);
}
textarea, input, select, .gr-box {
  background-color: white !important;
  color: #111827 !important;
  border: 1.5px solid #e2e8f0 !important;
  border-radius: 10px !important;
  box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}
label {
  color: #f8fafc !important;
  font-weight: 600 !important;
}
"""

with gr.Blocks(css=custom_css) as demo:
    gr.HTML("<div id='title-bar'>ğŸ§ AI Audio Transcriber + Multilingual Translator</div>")

    with gr.Row():
        with gr.Column(scale=1):
            audio_in = gr.Audio(
                sources=["upload", "microphone"],
                type="filepath",
                label="ğŸ™ Upload or Record Audio",
                waveform_options=None,
            )
            target_lang = gr.Dropdown(
                list(LANGUAGE_OPTIONS.keys()),
                value="Bangla / Bengali",
                label="ğŸŒ Translate To"
            )
            go_btn = gr.Button("ğŸš€ Transcribe + Translate")

        with gr.Column(scale=1):
            status = gr.Textbox(label="ğŸŸ¢ Status", interactive=False)
            text_out = gr.Textbox(label="ğŸ“ Transcribed Text", lines=6)
            trans_out = gr.Textbox(label="ğŸŒ Translated Text", lines=6)

    go_btn.click(fn=process, inputs=[audio_in, target_lang],
                 outputs=[status, text_out, trans_out],
                 show_progress=True)

           # ğŸ’» Developer section (centered at bottom)
   # Footer
    gr.HTML("""
<div align="center">

**ğŸ§‘â€ğŸ’»ğŸ§‘â€ğŸ’»ğŸ§‘â€ğŸ’»ğŸ§‘â€ğŸ’» **
<h3>ğŸ§‘â€ğŸ’» Developed by :Md. Ferdaus HossenğŸ§‘â€ğŸ’»</h3>
<h5>Junior AI/ML Engineer at Zensoft Lab</h5>

<p>
  <a href="https://github.com/Ferdaus71" target="_blank" style="margin-right:10px;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/github.svg" width="25" height="25" alt="GitHub">
  </a>
  <a href="https://www.linkedin.com/in/ferdaus70/" target="_blank" style="margin-left:10px;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/linkedin.svg" width="25" height="25" alt="LinkedIn">
  </a>
</p>

</div>
""")

print("ğŸŒˆ Launching App with White Boxes UI...")
demo.launch(share=True)